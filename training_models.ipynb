{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd70698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import svd\n",
    "import uuid\n",
    "import torch\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Step 1: Define System and Simulation Parameters\n",
    "N = 64  # Number of BS antennas\n",
    "K = 4   # Number of users\n",
    "M = 4   # Number of RF chains\n",
    "omega = 0.3  # Tradeoff weight\n",
    "\n",
    "I_max = 120  # Maximum outer iterations\n",
    "sigma_n2 = 1.0  # Noise variance\n",
    "mu = 0.01  # Step size for analog precoder\n",
    "lambda_ = 0.01  # Step size for digital precoder\n",
    "L = 20  # Number of paths for channel\n",
    "\n",
    "# Convert to tensors\n",
    "omega_t = torch.tensor(omega, dtype=torch.float32, device=device)\n",
    "sigma_n2_t = torch.tensor(sigma_n2, dtype=torch.float32, device=device)\n",
    "mu_t = torch.tensor(mu, dtype=torch.float32, device=device)\n",
    "lambda_t = torch.tensor(lambda_, dtype=torch.float32, device=device)\n",
    "\n",
    "# Step 2: Define Sensing Parameters\n",
    "P = 3  # Number of desired sensing angles\n",
    "theta_d = np.array([-60, 0, 60]) * np.pi / 180  # Desired angles in radians\n",
    "delta_theta = 5 * np.pi / 180  # Half beamwidth\n",
    "theta_grid = np.linspace(-np.pi / 2, np.pi / 2, 181)  # Angular grid [-90, 90] degrees\n",
    "B_d = np.zeros(len(theta_grid))  # Desired beampattern\n",
    "for t, theta_t in enumerate(theta_grid):\n",
    "    for theta_p in theta_d:\n",
    "        if abs(theta_t - theta_p) <= delta_theta:\n",
    "            B_d[t] = 1\n",
    "\n",
    "# Convert to tensors\n",
    "theta_d_t = torch.tensor(theta_d, dtype=torch.float32, device=device)\n",
    "theta_grid_t = torch.tensor(theta_grid, dtype=torch.float32, device=device)\n",
    "B_d_t = torch.tensor(B_d, dtype=torch.float32, device=device)\n",
    "\n",
    "# Wavenumber and antenna spacing\n",
    "lambda_wave = 1  # Wavelength (normalized)\n",
    "k = 2 * np.pi / lambda_wave\n",
    "d = lambda_wave / 2  # Antenna spacing\n",
    "\n",
    "k_t = torch.tensor(k, dtype=torch.float32, device=device)\n",
    "d_t = torch.tensor(d, dtype=torch.float32, device=device)\n",
    "\n",
    "import h5py\n",
    "SNR_dB_array = np.arange(0, 12.1, 0.1)\n",
    "# Load Psi data (from MATLAB .mat file)\n",
    "with h5py.File('Psi_all.mat', 'r') as f:\n",
    "    Psi_h5 = f['Psi_all']\n",
    "\n",
    "    # If stored as MATLAB complex structure (real/imag parts separate)\n",
    "    if np.issubdtype(Psi_h5.dtype, np.void):\n",
    "        real = Psi_h5['real'][()]\n",
    "        imag = Psi_h5['imag'][()]\n",
    "        Psi_all = real + 1j * imag\n",
    "    else:\n",
    "        Psi_all = np.array(Psi_h5)\n",
    "\n",
    "# Ensure Psi_all has shape: (num_SNRs, M, N)\n",
    "Psi_all = np.squeeze(Psi_all)  # remove singleton dimensions if any\n",
    "\n",
    "\n",
    "def compute_psi(snr_db):\n",
    "    \"\"\"\n",
    "    Selects the Psi matrix corresponding to the closest SNR value.\n",
    "    \"\"\"\n",
    "    # Find index of closest SNR\n",
    "    idx = np.argmin(np.abs(SNR_dB_array - snr_db))\n",
    "\n",
    "    # Select corresponding Psi  \n",
    "    Psi = Psi_all[idx, :, :]\n",
    "\n",
    "    return Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e666e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gx/jn94vn6n4kx19gx4401mwj580000gn/T/ipykernel_31015/3581630800.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  P_BS_t = torch.tensor(P_BS, dtype=torch.float32, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training UPGANet (J=10)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==== Config ====\n",
    "num_epochs = 30\n",
    "num_channels = 1000\n",
    "snr_min, snr_max = 0, 12\n",
    "\n",
    "from lib.dnn import UPGANet, upganet_loss\n",
    "from lib.support_functions_torch import (\n",
    "    generate_channel_torch_batch,\n",
    "    proposed_initialization_torch_batch_multiSNR\n",
    ")\n",
    "\n",
    "# print(f\"Training config: epochs={num_epochs}, channels/epoch={num_channels}, SNR={snr_max} dB\")\n",
    "\n",
    "\n",
    "# snr_db = snr_max\n",
    "snr_min, snr_max, snr_step = 0, 12, 2\n",
    "snr_range = torch.arange(snr_min, snr_max + snr_step, snr_step)\n",
    "\n",
    "\n",
    "P_BS_list = []\n",
    "\n",
    "for snr_db in snr_range:\n",
    "    P_BS = sigma_n2 * 10**(snr_db / 10)\n",
    "    P_BS_t = torch.tensor(P_BS, dtype=torch.float32, device=device)\n",
    "\n",
    "    P_BS_list.append(P_BS_t)\n",
    "\n",
    "# # ==== Pre-generate channel batch ====\n",
    "# H_batch = generate_channel_batch(N, M, L=20, batch_size=num_channels, device=device)\n",
    "# print(f\"Channel batch shape: {H_batch.shape}\")\n",
    "\n",
    "# ==== Training ====\n",
    "J_values = [10]\n",
    "\n",
    "for J in J_values:\n",
    "    print(f\"\\nTraining UPGANet (J={J})\")\n",
    "    model = UPGANet(N, M, K, omega, I_max=I_max, J=J).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)#for J= 1\n",
    "    decay_rate = 0.97\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=0.001) #for J= 10\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=decay_rate)\n",
    "\n",
    "\n",
    "    loss_history, mu_history, lambda_history = [], [], []\n",
    "    H_batch = generate_channel_torch_batch(N, M, L=20, batch_size=num_channels, device=device)\n",
    "    A0, D0, P_BS_used = proposed_initialization_torch_batch_multiSNR(H_batch, theta_d_t, N, M, K, P_BS_list, device=device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for ch_idx in range(num_channels):\n",
    "            H_ch = H_batch[ch_idx]\n",
    "            A0_ch = A0[ch_idx]\n",
    "            D0_ch = D0[ch_idx]\n",
    "            P_BS_t = P_BS_used[ch_idx]\n",
    "\n",
    "            Psi = compute_psi(P_BS_t.cpu().item() / sigma_n2 * 10)  # Convert back to SNR in dB\n",
    "            Psi = torch.tensor(Psi, dtype=torch.complex64, device=device)\n",
    "            \n",
    "            # A0, D0 = proposed_initialization_torch(H_ch, theta_d_t, N, M, K, P_BS_t, device=device)\n",
    "            A_final, D_final = model(H_ch, A0_ch, D0_ch, Psi, sigma_n2_t, P_BS_t)\n",
    "\n",
    "            loss = upganet_loss(H_ch, A_final, D_final, Psi, sigma_n2_t, omega)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / num_channels\n",
    "        loss_history.append(avg_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mu_mean = model.layers[0].mu.mean().item()\n",
    "            lambda_val = model.layers[0].lambda_.item()\n",
    "        mu_history.append(mu_mean)\n",
    "        lambda_history.append(lambda_val)\n",
    "        scheduler.step()\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss: {avg_loss:.6f} | μ={mu_mean:.6f}, λ={lambda_val:.6f}\")\n",
    "\n",
    "    # ==== Save model ====\n",
    "    save_path = f\"upganet_J{J}_final.pth\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved: {save_path}\")\n",
    "\n",
    "    # ==== Plot results ====\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "    axes[0].plot(loss_history, linewidth=2)\n",
    "    axes[0].set_title(\"Training Loss\")\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[1].plot(mu_history, linewidth=2, color=\"orange\")\n",
    "    axes[1].set_title(\"Learned Step Size μ\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[2].plot(lambda_history, linewidth=2, color=\"green\")\n",
    "    axes[2].set_title(\"Learned Step Size λ\")\n",
    "    axes[2].set_xlabel(\"Epoch\")\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nTraining complete ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c748bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05821558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
