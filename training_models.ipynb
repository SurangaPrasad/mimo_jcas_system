{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cd70698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import svd\n",
    "import uuid\n",
    "import torch\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Step 1: Define System and Simulation Parameters\n",
    "N = 64  # Number of BS antennas\n",
    "K = 4   # Number of users\n",
    "M = 4   # Number of RF chains\n",
    "omega = 0.3  # Tradeoff weight\n",
    "\n",
    "I_max = 120  # Maximum outer iterations\n",
    "sigma_n2 = 1.0  # Noise variance\n",
    "mu = 0.01  # Step size for analog precoder\n",
    "lambda_ = 0.01  # Step size for digital precoder\n",
    "L = 20  # Number of paths for channel\n",
    "\n",
    "# Convert to tensors\n",
    "omega_t = torch.tensor(omega, dtype=torch.float32, device=device)\n",
    "sigma_n2_t = torch.tensor(sigma_n2, dtype=torch.float32, device=device)\n",
    "mu_t = torch.tensor(mu, dtype=torch.float32, device=device)\n",
    "lambda_t = torch.tensor(lambda_, dtype=torch.float32, device=device)\n",
    "\n",
    "# Step 2: Define Sensing Parameters\n",
    "P = 3  # Number of desired sensing angles\n",
    "theta_d = np.array([-60, 0, 60]) * np.pi / 180  # Desired angles in radians\n",
    "delta_theta = 5 * np.pi / 180  # Half beamwidth\n",
    "theta_grid = np.linspace(-np.pi / 2, np.pi / 2, 181)  # Angular grid [-90, 90] degrees\n",
    "B_d = np.zeros(len(theta_grid))  # Desired beampattern\n",
    "for t, theta_t in enumerate(theta_grid):\n",
    "    for theta_p in theta_d:\n",
    "        if abs(theta_t - theta_p) <= delta_theta:\n",
    "            B_d[t] = 1\n",
    "\n",
    "# Convert to tensors\n",
    "theta_d_t = torch.tensor(theta_d, dtype=torch.float32, device=device)\n",
    "theta_grid_t = torch.tensor(theta_grid, dtype=torch.float32, device=device)\n",
    "B_d_t = torch.tensor(B_d, dtype=torch.float32, device=device)\n",
    "\n",
    "# Wavenumber and antenna spacing\n",
    "lambda_wave = 1  # Wavelength (normalized)\n",
    "k = 2 * np.pi / lambda_wave\n",
    "d = lambda_wave / 2  # Antenna spacing\n",
    "\n",
    "k_t = torch.tensor(k, dtype=torch.float32, device=device)\n",
    "d_t = torch.tensor(d, dtype=torch.float32, device=device)\n",
    "\n",
    "import h5py\n",
    "SNR_dB_array = np.arange(0, 12.1, 0.1)\n",
    "# Load Psi data (from MATLAB .mat file)\n",
    "with h5py.File('Psi_all.mat', 'r') as f:\n",
    "    Psi_h5 = f['Psi_all']\n",
    "\n",
    "    # If stored as MATLAB complex structure (real/imag parts separate)\n",
    "    if np.issubdtype(Psi_h5.dtype, np.void):\n",
    "        real = Psi_h5['real'][()]\n",
    "        imag = Psi_h5['imag'][()]\n",
    "        Psi_all = real + 1j * imag\n",
    "    else:\n",
    "        Psi_all = np.array(Psi_h5)\n",
    "\n",
    "# Ensure Psi_all has shape: (num_SNRs, M, N)\n",
    "Psi_all = np.squeeze(Psi_all)  # remove singleton dimensions if any\n",
    "\n",
    "\n",
    "def compute_psi(snr_db):\n",
    "    \"\"\"\n",
    "    Selects the Psi matrix corresponding to the closest SNR value.\n",
    "    \"\"\"\n",
    "    # Find index of closest SNR\n",
    "    idx = np.argmin(np.abs(SNR_dB_array - snr_db))\n",
    "\n",
    "    # Select corresponding Psi  \n",
    "    Psi = Psi_all[idx, :, :]\n",
    "\n",
    "    return Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e666e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3893321/467556693.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  P_BS_t = torch.tensor(P_BS, dtype=torch.float32, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training UPGANet (J=10)\n",
      "Epoch [1/30] | Loss: 55.829961 | μ=0.021512, λ=-0.009596\n",
      "Epoch [2/30] | Loss: 56.522087 | μ=0.042546, λ=0.016392\n",
      "Epoch [3/30] | Loss: 54.926397 | μ=0.070009, λ=0.025293\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==== Config ====\n",
    "num_epochs = 30\n",
    "num_channels = 500\n",
    "\n",
    "from lib.dnn import UPGANet, upganet_loss\n",
    "from lib.support_functions_torch import (\n",
    "    generate_channel_torch_batch,\n",
    "    proposed_initialization_torch_batch_multiSNR\n",
    ")\n",
    "\n",
    "# print(f\"Training config: epochs={num_epochs}, channels/epoch={num_channels}, SNR={snr_max} dB\")\n",
    "\n",
    "\n",
    "# snr_db = snr_max\n",
    "snr_min, snr_max, snr_step = 12, 12, 2\n",
    "snr_range = torch.arange(snr_min, snr_max + snr_step, snr_step)\n",
    "\n",
    "\n",
    "P_BS_list = []\n",
    "\n",
    "for snr_db in snr_range:\n",
    "    P_BS = sigma_n2 * 10**(snr_db / 10)\n",
    "    P_BS_t = torch.tensor(P_BS, dtype=torch.float32, device=device)\n",
    "\n",
    "    P_BS_list.append(P_BS_t)\n",
    "\n",
    "# # ==== Pre-generate channel batch ====\n",
    "# H_batch = generate_channel_batch(N, M, L=20, batch_size=num_channels, device=device)\n",
    "# print(f\"Channel batch shape: {H_batch.shape}\")\n",
    "\n",
    "# ==== Training ====\n",
    "J_values = [10]\n",
    "\n",
    "for J in J_values:\n",
    "    print(f\"\\nTraining UPGANet (J={J})\")\n",
    "    model = UPGANet(N, M, K, omega, I_max=I_max, J=J).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)#for J= 1\n",
    "    decay_rate = 0.97\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=0.001) #for J= 10\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=decay_rate)\n",
    "\n",
    "\n",
    "    loss_history, mu_history, lambda_history = [], [], []\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        H_batch = generate_channel_torch_batch(N, M, L=20, batch_size=num_channels, device=device)\n",
    "        A0, D0, P_BS_used = proposed_initialization_torch_batch_multiSNR(H_batch, theta_d_t, N, M, K, P_BS_list, device=device)\n",
    "        total_loss = 0.0\n",
    "        for ch_idx in range(num_channels):\n",
    "            H_ch = H_batch[ch_idx]\n",
    "            A0_ch = A0[ch_idx]\n",
    "            D0_ch = D0[ch_idx]\n",
    "            P_BS_t = P_BS_used[ch_idx]\n",
    "\n",
    "            Psi = compute_psi(P_BS_t.cpu().item() / sigma_n2 * 10)  # Convert back to SNR in dB\n",
    "            Psi = torch.tensor(Psi, dtype=torch.complex64, device=device)\n",
    "            \n",
    "            # A0, D0 = proposed_initialization_torch(H_ch, theta_d_t, N, M, K, P_BS_t, device=device)\n",
    "            A_final, D_final = model(H_ch, A0_ch, D0_ch, Psi, sigma_n2_t, P_BS_t)\n",
    "\n",
    "            loss = upganet_loss(H_ch, A_final, D_final, Psi, sigma_n2_t, omega)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / num_channels\n",
    "        loss_history.append(avg_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mu_mean = model.layers[0].mu.mean().item()\n",
    "            lambda_val = model.layers[0].lambda_.item()\n",
    "        mu_history.append(mu_mean)\n",
    "        lambda_history.append(lambda_val)\n",
    "        scheduler.step()\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss: {avg_loss:.6f} | μ={mu_mean:.6f}, λ={lambda_val:.6f}\")\n",
    "\n",
    "    # ==== Save model ====\n",
    "    save_path = f\"upganet_J{J}_final.pth\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved: {save_path}\")\n",
    "\n",
    "    # ==== Plot results ====\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "    axes[0].plot(loss_history, linewidth=2)\n",
    "    axes[0].set_title(\"Training Loss\")\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[1].plot(mu_history, linewidth=2, color=\"orange\")\n",
    "    axes[1].set_title(\"Learned Step Size μ\")\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[2].plot(lambda_history, linewidth=2, color=\"green\")\n",
    "    axes[2].set_title(\"Learned Step Size λ\")\n",
    "    axes[2].set_xlabel(\"Epoch\")\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nTraining complete ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf41696c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c748bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EVALUATING UNTRAINED UPGANet (μ=-0.176042, λ=0.021704, J=1)\n",
      "======================================================================\n",
      "Device: cpu\n",
      "\n",
      "SNR =  0 dB → Avg R = 2.3815 bps/Hz\n",
      "SNR =  2 dB → Avg R = 2.4429 bps/Hz\n",
      "SNR =  4 dB → Avg R = 2.7596 bps/Hz\n",
      "SNR =  6 dB → Avg R = 2.7351 bps/Hz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m R_untrained_list\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Evaluate untrained (μ=λ=0.01)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m untrained_results = \u001b[43mevaluate_untrained_upganet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmu_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m0.176042\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_val\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.021704\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mJ\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_realizations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnr_range\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m13\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# ==== Plot comparison ====\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mevaluate_untrained_upganet\u001b[39m\u001b[34m(mu_val, lambda_val, J, num_realizations, snr_range)\u001b[39m\n\u001b[32m     44\u001b[39m A0, D0 = proposed_initialization_torch(H_t, theta_d_t, N, M, K, P_BS_t, device=device)\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     A_final, D_final = \u001b[43muntrained_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPsi_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_n2_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP_BS_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Compute achievable rate\u001b[39;00m\n\u001b[32m     50\u001b[39m R = compute_rate_torch(H_t, A_final, D_final, sigma_n2_t)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OneDrive/PHD Thesis/mimo_jcas_system/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OneDrive/PHD Thesis/mimo_jcas_system/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OneDrive/PHD Thesis/mimo_jcas_system/lib/dnn.py:86\u001b[39m, in \u001b[36mUPGANet.forward\u001b[39m\u001b[34m(self, H, A0, D0, Psi, sigma_n2, P_BS)\u001b[39m\n\u001b[32m     84\u001b[39m A, D = A0, D0\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.I_max):\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     A, D = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPsi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_n2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP_BS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m A, D\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OneDrive/PHD Thesis/mimo_jcas_system/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OneDrive/PHD Thesis/mimo_jcas_system/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OneDrive/PHD Thesis/mimo_jcas_system/lib/dnn.py:55\u001b[39m, in \u001b[36mUPGANetLayer.forward\u001b[39m\u001b[34m(self, H, A, D, Psi, sigma_n2, P_BS)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Digital precoder update\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# DETACH gradient computations here too\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     grad_RD = \u001b[43mgradient_R_D_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_n2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     grad_tauD = gradient_tau_D_torch(A, D, Psi)\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Gradient ascent with learnable step size\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/OneDrive/PHD Thesis/mimo_jcas_system/lib/support_functions_torch.py:148\u001b[39m, in \u001b[36mgradient_R_D_torch\u001b[39m\u001b[34m(H, A, D, sigma_n2, eps, clip_value)\u001b[39m\n\u001b[32m    145\u001b[39m     term1 = (H_bar_k @ D) / denom1\n\u001b[32m    146\u001b[39m     term2 = (H_bar_k @ D_bar_k) / denom2\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     grad_D += xi * (term1 - term2)\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# Clip gradients to prevent explosion\u001b[39;00m\n\u001b[32m    151\u001b[39m grad_norm = torch.linalg.norm(grad_D, \u001b[38;5;28mord\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mfro\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from lib.dnn import UPGANet\n",
    "from lib.support_functions_torch import (\n",
    "    compute_rate_torch,\n",
    "    generate_channel_torch_batch,\n",
    "    proposed_initialization_torch,\n",
    "    compute_psi\n",
    ")\n",
    "\n",
    "def evaluate_untrained_upganet(mu_val=0.01, lambda_val=0.01, J=1, num_realizations=100, snr_range=range(0, 13, 2)):\n",
    "    \"\"\"\n",
    "    Evaluate an untrained UPGANet model with fixed μ and λ values\n",
    "    to compute the average achievable rate vs SNR.\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(f\"EVALUATING UNTRAINED UPGANet (μ={mu_val}, λ={lambda_val}, J={J})\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Device: {device}\\n\")\n",
    "\n",
    "    # Instantiate untrained model\n",
    "    untrained_model = UPGANet(N, M, K, omega, I_max=I_max, J=J).to(device)\n",
    "\n",
    "    # Set μ and λ manually\n",
    "    with torch.no_grad():\n",
    "        for layer in untrained_model.layers:\n",
    "            layer.mu.data.fill_(mu_val)\n",
    "            layer.lambda_.data.fill_(lambda_val)\n",
    "\n",
    "    untrained_model.eval()\n",
    "\n",
    "    R_untrained_list = []\n",
    "\n",
    "    for snr_db in snr_range:\n",
    "        R_sum = 0.0\n",
    "        P_BS = sigma_n2 * 10**(snr_db / 10)\n",
    "        P_BS_t = torch.tensor(P_BS, dtype=torch.float32, device=device)\n",
    "        Psi_t = torch.tensor(compute_psi(snr_db), dtype=torch.cfloat, device=device)\n",
    "        H_batch = generate_channel_torch_batch(N, M, L=20, batch_size=num_realizations, device=device)\n",
    "\n",
    "        for realization in range(num_realizations):\n",
    "            H_t = H_batch[realization]\n",
    "\n",
    "            # Initialization (same as in training)\n",
    "            A0, D0 = proposed_initialization_torch(H_t, theta_d_t, N, M, K, P_BS_t, device=device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                A_final, D_final = untrained_model(H_t, A0, D0, Psi_t, sigma_n2_t, P_BS_t)\n",
    "\n",
    "            # Compute achievable rate\n",
    "            R = compute_rate_torch(H_t, A_final, D_final, sigma_n2_t)\n",
    "            R_sum += R.item()\n",
    "\n",
    "        R_avg = R_sum / num_realizations\n",
    "        R_untrained_list.append(R_avg)\n",
    "        print(f\"SNR = {snr_db:2d} dB → Avg R = {R_avg:.4f} bps/Hz\")\n",
    "\n",
    "    return R_untrained_list\n",
    "\n",
    "\n",
    "# Evaluate untrained (μ=λ=0.01)\n",
    "untrained_results = evaluate_untrained_upganet(\n",
    "    mu_val=-0.176042, lambda_val=0.021704, J=1,\n",
    "    num_realizations=100, snr_range=range(0, 13, 2)\n",
    ")\n",
    "\n",
    "# ==== Plot comparison ====\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "snr_vals = list(range(0, 13, 2))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(snr_vals, untrained_results, 'o--', label='Untrained (μ=λ=0.01)')\n",
    "# plt.plot(snr_vals, trained_results, 's-', label='Trained UPGANet')\n",
    "plt.xlabel('SNR (dB)')\n",
    "plt.ylabel('Average Achievable Rate (bps/Hz)')\n",
    "plt.title('UPGANet Performance: Before vs After Training')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05821558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
